import os
import hashlib
import streamlit as st

@st.cache_data
def load_wordlist():
    with open("bip39_english.txt", "r", encoding="utf-8") as f:
        return [word.strip() for word in f.readlines()]

def generate_entropy(entropy_bits):
    entropy = os.urandom(entropy_bits // 8)
    entropy_hex = entropy.hex()
    entropy_bin = bin(int.from_bytes(entropy, 'big'))[2:].zfill(entropy_bits)
    return entropy, entropy_hex, entropy_bin

def sha256_checksum(entropy):
    digest = hashlib.sha256(entropy).digest()
    digest_hex = digest.hex()
    digest_bin = bin(int.from_bytes(digest, 'big'))[2:].zfill(256)
    return digest, digest_hex, digest_bin

def build_full_bitstring(entropy_bin, checksum_bin, checksum_len):
    return entropy_bin + checksum_bin[:checksum_len]

def split_into_chunks(bits, chunk_size=11):
    return [bits[i:i+chunk_size] for i in range(0, len(bits), chunk_size)]

def main():
    st.title("ğŸ” BIP-39 ë‹ˆëª¨ë‹‰ ìƒì„±ê¸° (ì¤‘ê°„ ê³¼ì • ë³´ê¸°)")
    st.markdown("ì´ ì•±ì€ BIP-39 í‘œì¤€ì— ë”°ë¼ ë‹ˆëª¨ë‹‰ ì½”ë“œì™€ ìƒì„± ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.")

    word_count = st.selectbox("ì›í•˜ëŠ” ë‹ˆëª¨ë‹‰ ë‹¨ì–´ ìˆ˜", [12, 15, 18, 21, 24])
    entropy_bits = {12: 128, 15: 160, 18: 192, 21: 224, 24: 256}[word_count]
    checksum_len = entropy_bits // 32

    if st.button("ğŸ² ë‹ˆëª¨ë‹‰ ìƒì„±í•˜ê¸°"):
        wordlist = load_wordlist()

        # Step 1: ì—”íŠ¸ë¡œí”¼ ìƒì„±
        entropy, entropy_hex, entropy_bin = generate_entropy(entropy_bits)
        st.subheader("1. ì—”íŠ¸ë¡œí”¼")
        st.text(f"[Hex]  {entropy_hex}")
        st.text(f"[Bin]  {entropy_bin}")

        # Step 2: SHA-256 í•´ì‹œ â†’ ì²´í¬ì„¬
        digest, digest_hex, digest_bin = sha256_checksum(entropy)
        checksum = digest_bin[:checksum_len]
        st.subheader("2. SHA-256 í•´ì‹œ â†’ ì²´í¬ì„¬")
        st.text(f"[SHA-256 Hex] {digest_hex}")
        st.text(f"[ì²´í¬ì„¬ ë¹„íŠ¸ ìˆ˜] {checksum_len} bits")
        st.text(f"[ì²´í¬ì„¬ (Bin)]  {checksum}")

        # Step 3: ìµœì¢… ë¹„íŠ¸ì—´ ë§Œë“¤ê¸°
        final_bits = build_full_bitstring(entropy_bin, checksum, checksum_len)
        st.subheader("3. ì—”íŠ¸ë¡œí”¼ + ì²´í¬ì„¬ â†’ ìµœì¢… ë¹„íŠ¸ì—´")
        st.text(final_bits)

        # Step 4: 11ë¹„íŠ¸ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
        chunks = split_into_chunks(final_bits)
        st.subheader("4. 11ë¹„íŠ¸ ë¸”ë¡ â†’ ë‹¨ì–´ ì¸ë±ìŠ¤ & ë‹¨ì–´")
        for i, chunk in enumerate(chunks):
            idx = int(chunk, 2)
            word = wordlist[idx]
            st.text(f"{i+1:02d}. [{chunk}] â†’ {idx} â†’ {word}")

        # Step 5: ìµœì¢… ë‹ˆëª¨ë‹‰
        st.subheader("ìµœì¢… ë‹ˆëª¨ë‹‰ ì½”ë“œ")
        mnemonic = [wordlist[int(chunk, 2)] for chunk in chunks]
        st.code(" ".join(mnemonic), language="text")

if __name__ == "__main__":
    main()